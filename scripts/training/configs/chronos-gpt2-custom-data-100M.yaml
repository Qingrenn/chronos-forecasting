training_data_paths:
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/alibaba_cluster_trace_2018'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/AtrialFibrillation'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/australian_electricity_demand'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/azure_vm_traces_2017'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/bdg-2_bear'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/bdg-2_fox'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/bdg-2_panther'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/BIDMC32HR'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/borg_cluster_data_2011'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/buildings_900k'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/cmip6_1850'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/cmip6_1855'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/covid19_energy'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/elecdemand'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/elf'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/era5_1989'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/era5_1990'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/favorita_sales'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/gfc14_load'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/gfc17_load'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/IEEEPPG'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/kaggle_web_traffic_weekly'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/largest_2017'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/largest_2018'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/largest_2019'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/largest_2020'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/largest_2021'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/LOOP_SEATTLE'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/MotorImagery'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/pdb'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/PEMS_BAY'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/PEMS04'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/PEMS07'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/PEMS08'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/PigArtPressure'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/PigCVP'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/Q-TRAFFIC'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/sceaux'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/SelfRegulationSCP1'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/SelfRegulationSCP2'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/solar_power'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/spain'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/TDBrain'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/traffic_weekly'
- '/home/qingrenyao/archive/chronos-forecasting/Lotsa16B_uni/wiki-rolling_nips'
probability:
- 0.011373
- 0.000002
- 0.000068
- 0.052508
- 0.000088
- 0.000138
- 0.000055
- 0.003772
- 0.063622
- 0.279880
- 0.085132
- 0.085132
- 0.000002
- 0.000001
- 0.000001
- 0.055184
- 0.055184
- 0.008252
- 0.000001
- 0.000008
- 0.000918
- 0.000981
- 0.051104
- 0.052551
- 0.053623
- 0.053526
- 0.053299
- 0.002014
- 0.004305
- 0.000001
- 0.001005
- 0.000928
- 0.001478
- 0.000540
- 0.000037
- 0.000037
- 0.015682
- 0.000002
- 0.000179
- 0.000182
- 0.000439
- 0.000002
- 0.004348
- 0.000005
- 0.002408
n_layer: 18
n_embd: 768
n_head: 12
context_length: 512
prediction_length: 64
min_past: 60
max_steps: 200_000
save_steps: 100_000
log_steps: 500
per_device_train_batch_size: 32
learning_rate: 0.001
optim: adamw_torch_fused
num_samples: 20
shuffle_buffer_length: 100_000
gradient_accumulation_steps: 1
model_id: openai-community/gpt2
model_type: causal
random_init: true
tie_embeddings: true
output_dir: ./output/
tf32: true
torch_compile: true
tokenizer_class: "MeanScaleUniformBins"
tokenizer_kwargs:
  low_limit: -15.0
  high_limit: 15.0
n_tokens: 4096
lr_scheduler_type: linear
warmup_ratio: 0.0
dataloader_num_workers: 1
max_missing_prop: 0.1
use_eos_token: true
